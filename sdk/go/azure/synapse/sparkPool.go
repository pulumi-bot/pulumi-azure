// *** WARNING: this file was generated by the Pulumi Terraform Bridge (tfgen) Tool. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

package synapse

import (
	"reflect"

	"github.com/pkg/errors"
	"github.com/pulumi/pulumi/sdk/v2/go/pulumi"
)

// Manages a Synapse Spark Pool.
type SparkPool struct {
	pulumi.CustomResourceState

	// An `autoPause` block as defined below.
	AutoPause SparkPoolAutoPausePtrOutput `pulumi:"autoPause"`
	// An `autoScale` block as defined below. Exactly one of `nodeCount` or `autoScale` must be specified.
	AutoScale SparkPoolAutoScalePtrOutput `pulumi:"autoScale"`
	// A `libraryRequirement` block as defined below.
	LibraryRequirement SparkPoolLibraryRequirementPtrOutput `pulumi:"libraryRequirement"`
	// The name which should be used for this Synapse Spark Pool. Changing this forces a new Synapse Spark Pool to be created.
	Name pulumi.StringOutput `pulumi:"name"`
	// The number of nodes in the Spark Pool. Exactly one of `nodeCount` or `autoScale` must be specified.
	NodeCount pulumi.IntPtrOutput `pulumi:"nodeCount"`
	// The level of node in the Spark Pool. Possible value is `Small`, `Medium` and `Large`.
	NodeSize pulumi.StringOutput `pulumi:"nodeSize"`
	// The kind of nodes that the Spark Pool provides. Possible value is `MemoryOptimized`.
	NodeSizeFamily pulumi.StringOutput `pulumi:"nodeSizeFamily"`
	// The Spark events folder. Defaults to `/events`.
	SparkEventsFolder pulumi.StringPtrOutput `pulumi:"sparkEventsFolder"`
	// The default folder where Spark logs will be written. Defaults to `/logs`.
	SparkLogFolder pulumi.StringPtrOutput `pulumi:"sparkLogFolder"`
	// The Apache Spark version. Possible value is `2.4`. Defaults to `2.4`.
	SparkVersion pulumi.StringPtrOutput `pulumi:"sparkVersion"`
	// The ID of the Synapse Workspace where the Synapse Spark Pool should exist. Changing this forces a new Synapse Spark Pool to be created.
	SynapseWorkspaceId pulumi.StringOutput `pulumi:"synapseWorkspaceId"`
	// A mapping of tags which should be assigned to the Synapse Spark Pool.
	Tags pulumi.StringMapOutput `pulumi:"tags"`
}

// NewSparkPool registers a new resource with the given unique name, arguments, and options.
func NewSparkPool(ctx *pulumi.Context,
	name string, args *SparkPoolArgs, opts ...pulumi.ResourceOption) (*SparkPool, error) {
	if args == nil || args.NodeSize == nil {
		return nil, errors.New("missing required argument 'NodeSize'")
	}
	if args == nil || args.NodeSizeFamily == nil {
		return nil, errors.New("missing required argument 'NodeSizeFamily'")
	}
	if args == nil || args.SynapseWorkspaceId == nil {
		return nil, errors.New("missing required argument 'SynapseWorkspaceId'")
	}
	if args == nil {
		args = &SparkPoolArgs{}
	}
	var resource SparkPool
	err := ctx.RegisterResource("azure:synapse/sparkPool:SparkPool", name, args, &resource, opts...)
	if err != nil {
		return nil, err
	}
	return &resource, nil
}

// GetSparkPool gets an existing SparkPool resource's state with the given name, ID, and optional
// state properties that are used to uniquely qualify the lookup (nil if not required).
func GetSparkPool(ctx *pulumi.Context,
	name string, id pulumi.IDInput, state *SparkPoolState, opts ...pulumi.ResourceOption) (*SparkPool, error) {
	var resource SparkPool
	err := ctx.ReadResource("azure:synapse/sparkPool:SparkPool", name, id, state, &resource, opts...)
	if err != nil {
		return nil, err
	}
	return &resource, nil
}

// Input properties used for looking up and filtering SparkPool resources.
type sparkPoolState struct {
	// An `autoPause` block as defined below.
	AutoPause *SparkPoolAutoPause `pulumi:"autoPause"`
	// An `autoScale` block as defined below. Exactly one of `nodeCount` or `autoScale` must be specified.
	AutoScale *SparkPoolAutoScale `pulumi:"autoScale"`
	// A `libraryRequirement` block as defined below.
	LibraryRequirement *SparkPoolLibraryRequirement `pulumi:"libraryRequirement"`
	// The name which should be used for this Synapse Spark Pool. Changing this forces a new Synapse Spark Pool to be created.
	Name *string `pulumi:"name"`
	// The number of nodes in the Spark Pool. Exactly one of `nodeCount` or `autoScale` must be specified.
	NodeCount *int `pulumi:"nodeCount"`
	// The level of node in the Spark Pool. Possible value is `Small`, `Medium` and `Large`.
	NodeSize *string `pulumi:"nodeSize"`
	// The kind of nodes that the Spark Pool provides. Possible value is `MemoryOptimized`.
	NodeSizeFamily *string `pulumi:"nodeSizeFamily"`
	// The Spark events folder. Defaults to `/events`.
	SparkEventsFolder *string `pulumi:"sparkEventsFolder"`
	// The default folder where Spark logs will be written. Defaults to `/logs`.
	SparkLogFolder *string `pulumi:"sparkLogFolder"`
	// The Apache Spark version. Possible value is `2.4`. Defaults to `2.4`.
	SparkVersion *string `pulumi:"sparkVersion"`
	// The ID of the Synapse Workspace where the Synapse Spark Pool should exist. Changing this forces a new Synapse Spark Pool to be created.
	SynapseWorkspaceId *string `pulumi:"synapseWorkspaceId"`
	// A mapping of tags which should be assigned to the Synapse Spark Pool.
	Tags map[string]string `pulumi:"tags"`
}

type SparkPoolState struct {
	// An `autoPause` block as defined below.
	AutoPause SparkPoolAutoPausePtrInput
	// An `autoScale` block as defined below. Exactly one of `nodeCount` or `autoScale` must be specified.
	AutoScale SparkPoolAutoScalePtrInput
	// A `libraryRequirement` block as defined below.
	LibraryRequirement SparkPoolLibraryRequirementPtrInput
	// The name which should be used for this Synapse Spark Pool. Changing this forces a new Synapse Spark Pool to be created.
	Name pulumi.StringPtrInput
	// The number of nodes in the Spark Pool. Exactly one of `nodeCount` or `autoScale` must be specified.
	NodeCount pulumi.IntPtrInput
	// The level of node in the Spark Pool. Possible value is `Small`, `Medium` and `Large`.
	NodeSize pulumi.StringPtrInput
	// The kind of nodes that the Spark Pool provides. Possible value is `MemoryOptimized`.
	NodeSizeFamily pulumi.StringPtrInput
	// The Spark events folder. Defaults to `/events`.
	SparkEventsFolder pulumi.StringPtrInput
	// The default folder where Spark logs will be written. Defaults to `/logs`.
	SparkLogFolder pulumi.StringPtrInput
	// The Apache Spark version. Possible value is `2.4`. Defaults to `2.4`.
	SparkVersion pulumi.StringPtrInput
	// The ID of the Synapse Workspace where the Synapse Spark Pool should exist. Changing this forces a new Synapse Spark Pool to be created.
	SynapseWorkspaceId pulumi.StringPtrInput
	// A mapping of tags which should be assigned to the Synapse Spark Pool.
	Tags pulumi.StringMapInput
}

func (SparkPoolState) ElementType() reflect.Type {
	return reflect.TypeOf((*sparkPoolState)(nil)).Elem()
}

type sparkPoolArgs struct {
	// An `autoPause` block as defined below.
	AutoPause *SparkPoolAutoPause `pulumi:"autoPause"`
	// An `autoScale` block as defined below. Exactly one of `nodeCount` or `autoScale` must be specified.
	AutoScale *SparkPoolAutoScale `pulumi:"autoScale"`
	// A `libraryRequirement` block as defined below.
	LibraryRequirement *SparkPoolLibraryRequirement `pulumi:"libraryRequirement"`
	// The name which should be used for this Synapse Spark Pool. Changing this forces a new Synapse Spark Pool to be created.
	Name *string `pulumi:"name"`
	// The number of nodes in the Spark Pool. Exactly one of `nodeCount` or `autoScale` must be specified.
	NodeCount *int `pulumi:"nodeCount"`
	// The level of node in the Spark Pool. Possible value is `Small`, `Medium` and `Large`.
	NodeSize string `pulumi:"nodeSize"`
	// The kind of nodes that the Spark Pool provides. Possible value is `MemoryOptimized`.
	NodeSizeFamily string `pulumi:"nodeSizeFamily"`
	// The Spark events folder. Defaults to `/events`.
	SparkEventsFolder *string `pulumi:"sparkEventsFolder"`
	// The default folder where Spark logs will be written. Defaults to `/logs`.
	SparkLogFolder *string `pulumi:"sparkLogFolder"`
	// The Apache Spark version. Possible value is `2.4`. Defaults to `2.4`.
	SparkVersion *string `pulumi:"sparkVersion"`
	// The ID of the Synapse Workspace where the Synapse Spark Pool should exist. Changing this forces a new Synapse Spark Pool to be created.
	SynapseWorkspaceId string `pulumi:"synapseWorkspaceId"`
	// A mapping of tags which should be assigned to the Synapse Spark Pool.
	Tags map[string]string `pulumi:"tags"`
}

// The set of arguments for constructing a SparkPool resource.
type SparkPoolArgs struct {
	// An `autoPause` block as defined below.
	AutoPause SparkPoolAutoPausePtrInput
	// An `autoScale` block as defined below. Exactly one of `nodeCount` or `autoScale` must be specified.
	AutoScale SparkPoolAutoScalePtrInput
	// A `libraryRequirement` block as defined below.
	LibraryRequirement SparkPoolLibraryRequirementPtrInput
	// The name which should be used for this Synapse Spark Pool. Changing this forces a new Synapse Spark Pool to be created.
	Name pulumi.StringPtrInput
	// The number of nodes in the Spark Pool. Exactly one of `nodeCount` or `autoScale` must be specified.
	NodeCount pulumi.IntPtrInput
	// The level of node in the Spark Pool. Possible value is `Small`, `Medium` and `Large`.
	NodeSize pulumi.StringInput
	// The kind of nodes that the Spark Pool provides. Possible value is `MemoryOptimized`.
	NodeSizeFamily pulumi.StringInput
	// The Spark events folder. Defaults to `/events`.
	SparkEventsFolder pulumi.StringPtrInput
	// The default folder where Spark logs will be written. Defaults to `/logs`.
	SparkLogFolder pulumi.StringPtrInput
	// The Apache Spark version. Possible value is `2.4`. Defaults to `2.4`.
	SparkVersion pulumi.StringPtrInput
	// The ID of the Synapse Workspace where the Synapse Spark Pool should exist. Changing this forces a new Synapse Spark Pool to be created.
	SynapseWorkspaceId pulumi.StringInput
	// A mapping of tags which should be assigned to the Synapse Spark Pool.
	Tags pulumi.StringMapInput
}

func (SparkPoolArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*sparkPoolArgs)(nil)).Elem()
}
